# هم‌راستاسازی هوش مصنوعی (AI Alignment)
![University](https://img.shields.io/badge/University-orange)
![AI Alignment](https://img.shields.io/badge/ai-Alignment-brightgreen)



<!-- Logo image -->
<img src="../images/AI Alignment LOGO.jpg" alt="logo"/>

## سرفصل‌های کلیدی:

هم‌راستاسازی هوش مصنوعی (AI Alignment)، حوزه‌ای حیاتی است که به دنبال یافتن روش‌های فنی و اخلاقی برای اطمینان از این است که سیستم‌های هوش مصنوعی پیشرفته، اهداف، ارزش‌ها و منافع انسان‌ها را دنبال می‌کنند. این ریپازیتوری مجموعه‌ای از منابع کلیدی، از جمله کتاب‌های مرجع، را برای درک عمیق این چالش وجودی و پیامدهای اجتماعی آن فراهم می‌آورد. هدف نهایی، هدایت توسعه‌ی هوش مصنوعی به سمتی است که برای بشریت ایمن، مفید و قابل اعتماد باشد.

| TAG | EN | FA | Description |
| :--- | :--- | :--- | :--- |
| ![Life 3.0](https://img.shields.io/badge/Life-3.0-green) | Life 3.0: Being Human in the Age of Artificial Intelligence | **مروری بر سناریوهای مختلف آینده‌ی هوش مصنوعی و اهمیت هم‌راستاسازی برای بقای بشر.** | زندگی ۳.۰: انسان بودن در عصر هوش مصنوعی |
| ![Human Compatible](https://img.shields.io/badge/Human-Compatible-00BCD4) | Human Compatible: Artificial Intelligence and the Problem of Control | **معرفی یک چارچوب عملی برای طراحی هوش مصنوعی ایمن که اهدافش با ارزش‌های انسانی منطبق باشد.** | سازگار با انسان: هوش مصنوعی و مسئله‌ی کنترل |
| ![Rebooting AI](https://img.shields.io/badge/Rebooting-AI-E57373) | Rebooting AI: Building Artificial Intelligence We Can Trust | **نقدی بر محدودیت‌های یادگیری عمیق فعلی و مسیرهای ساخت هوش مصنوعی با درک و استدلال قوی‌تر.** | راه‌اندازی مجدد هوش مصنوعی: ساخت هوش مصنوعی قابل اعتماد |
| ![Alignment Problem](https://img.shields.io/badge/Alignment-Problem-FFB300) | The Alignment Problem: Machine Learning and Human Values | **بررسی جامع چالش‌های فنی هم‌راستاسازی، شامل مسائل هدف‌گذاری و اکتشاف در سیستم‌های یادگیری ماشینی.** | مسئله‌ی هم‌راستاسازی: یادگیری ماشینی و ارزش‌های انسانی. |
| ![Superintelligence](https://img.shields.io/badge/Super-intelligence-FF8A65) | Superintelligence: Paths, Dangers, Strategies | **تحلیل تخصصی از خطرات بالقوه‌ی ابرهوش و نیاز فوری به استراتژی‌هایی برای کنترل آن پیش از وقوع.** | ابرهوش: مسیرها، خطرات، استراتژی‌ها |
| ![Weapons of Math](https://img.shields.io/badge/Weapons-Math-673AB7) | Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy | **نمایش اینکه چگونه الگوریتم‌های فعلی می‌توانند سوگیری‌ها را تقویت کرده و نابرابری‌های اجتماعی را عمیق‌تر سازند.** | سلاح‌های تخریب ریاضی: داده‌های بزرگ و نابرابری |
| ![Atlas of AI](https://img.shields.io/badge/Atlas-AI-009688) | Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence | **بررسی تأثیرات گسترده‌ی هوش مصنوعی بر جامعه، محیط زیست و ساختارهای قدرت سیاسی و اقتصادی.** | اطلس هوش مصنوعی: قدرت، سیاست و هزینه‌های سیاره‌ای |
| ![Master Algorithm](https://img.shields.io/badge/Master-Algorithm-0D47A1) | The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World | **توضیح مبانی و مکاتب مختلف یادگیری ماشینی که ساختارهای رفتاری هوش مصنوعی را شکل می‌دهند.** | الگوریتم اصلی: تلاش برای ساخت ماشین یادگیری نهایی |
| ![Value Alignment](https://img.shields.io/badge/Value-Alignment-B7410E) | Artificial Intelligence and the Value Alignment Problem | **تمرکز بر ابعاد فلسفی و اخلاقی هم‌راستاسازی و چگونگی کدگذاری ارزش‌های انسانی در ماشین‌ها.** | هوش مصنوعی و مسئله‌ی هم‌راستاسازی ارزش |
| ![Artificial Intelligence](https://img.shields.io/badge/Artificial-Intelligence-00BFA5) | Artificial Intelligence: A Modern Approach | **کتاب مرجع جامع برای فهم اصول نظری و عملی هوش مصنوعی و طراحی عامل‌های هوشمند.** | هوش مصنوعی: رویکردی نوین |
